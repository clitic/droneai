# ğŸš DroneAI â€” Anomaly Detection System

**Drone-as-First-Responder** anomaly detection using a two-stage pipeline: YOLOv26 object detection + GRU temporal classification.

![Python 3.14+](https://img.shields.io/badge/python-3.14%2B-blue)
![PyTorch](https://img.shields.io/badge/pytorch-2.10%2B-ee4c2c)
![Ultralytics](https://img.shields.io/badge/ultralytics-8.4%2B-00FFFF)
![License](https://img.shields.io/badge/license-MIT-green)

---

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Video Feed  â”‚ â”€â”€â–¶ â”‚  YOLOv26n (Stage 1) â”‚ â”€â”€â–¶ â”‚  GRU Classifier      â”‚
â”‚  / Frames    â”‚     â”‚  Object Detection   â”‚     â”‚  (Stage 3)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚  + Embedding        â”‚     â”‚  Temporal Anomaly    â”‚
                     â”‚  Extraction         â”‚     â”‚  Classification      â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚                           â”‚
                     Feature Vectors               Anomaly Prob.
                        (T, D)                     [0.0 â†’ 1.0]
```

**Stage 1** fine-tunes YOLOv26n on drone-perspective imagery (VisDrone) for robust aerial object detection. **Stage 2** extracts penultimate-layer embeddings from UCF-Crime video frames. **Stage 3** trains a bidirectional GRU with attention pooling to classify temporal sequences as Normal or Anomaly.

---

## Project Structure

```
droneai/
â”œâ”€â”€ datasets/
â”‚   â”œâ”€â”€ visdrone/              # VisDrone2019-DET dataset
â”‚   â”‚   â””â”€â”€ visdrone.yaml      # Dataset config
â”‚   â””â”€â”€ ufc-crime/             # UCF-Crime (pre-extracted frames)
â”‚       â”œâ”€â”€ Train/             # 14 category folders
â”‚       â””â”€â”€ Test/              # 14 category folders
â”œâ”€â”€ train_yolo.py              # Stage 1: Fine-tune YOLOv26n
â”œâ”€â”€ extract_features.py        # Stage 2: Embed frames â†’ .npy
â”œâ”€â”€ train_classifier.py        # Stage 3: GRU temporal classifier
â”œâ”€â”€ inference.py               # CLI end-to-end inference
â”œâ”€â”€ app.py                     # Gradio WebUI
â”œâ”€â”€ features/                  # Generated: .npy embeddings
â”œâ”€â”€ models/                    # Generated: GRU checkpoints
â”œâ”€â”€ runs/                      # Generated: YOLO training runs
â””â”€â”€ pyproject.toml
```

---

## Quick Start

### Prerequisites

- Python 3.14+
- CUDA-capable GPU (tested on RTX 3050)
- [uv](https://docs.astral.sh/uv/) package manager

### Installation

```bash
git clone <repo-url> droneai
cd droneai
uv sync
```

### Run the Pipeline

Execute each stage **in order**:

```bash
# Stage 1 â€” Fine-tune YOLOv26n on VisDrone
uv run python train_yolo.py --epochs 50 --batch 16

# Stage 2 â€” Extract embeddings from UCF-Crime frames
uv run python extract_features.py --batch-size 32

# Stage 3 â€” Train GRU anomaly classifier
uv run python train_classifier.py --epochs 30 --hidden-size 128
```

### Inference

**Gradio WebUI** (recommended):
```bash
uv run python app.py
# Open http://localhost:7860
```

**CLI**:
```bash
uv run python inference.py --source path/to/video.mp4 --save-video
```

---

## Pipeline Details

### Stage 1 â€” YOLO Fine-Tuning (`train_yolo.py`)

Fine-tunes YOLOv26n (nano) on VisDrone2019-DET for drone-perspective object detection across 10 classes: pedestrian, people, bicycle, car, van, truck, tricycle, awning-tricycle, bus, motor.

| Flag | Default | Description |
|------|---------|-------------|
| `--epochs` | 50 | Training epochs |
| `--batch` | 16 | Batch size |
| `--imgsz` | 640 | Input image size |
| `--device` | 0 | GPU device |
| `--cos-lr` | off | Cosine LR scheduler |
| `--patience` | 20 | Early stopping patience |

### Stage 2 â€” Feature Extraction (`extract_features.py`)

Runs `model.embed()` on UCF-Crime frames to extract penultimate-layer feature vectors. Frames are grouped by video clip, and each clip's features are saved as a `(T, D)` numpy array.

| Flag | Default | Description |
|------|---------|-------------|
| `--model` | `runs/detect/train/weights/best.pt` | YOLO weights |
| `--batch-size` | 16 | Inference batch size |
| `--max-frames` | 0 (all) | Cap frames per clip |

**Output:** `features/{Train,Test}/<Category>/<clip>.npy` + `features/manifest.json`

### Stage 3 â€” GRU Classifier (`train_classifier.py`)

Bidirectional GRU with learned attention pooling over time steps. Trained with class-weighted BCE loss (auto-balances Normal vs. Anomaly) and cosine-annealing LR.

| Flag | Default | Description |
|------|---------|-------------|
| `--hidden-size` | 128 | GRU hidden size |
| `--num-layers` | 2 | GRU depth |
| `--seq-len` | 64 | Fixed sequence length |
| `--lr` | 1e-4 | Learning rate |
| `--patience` | 10 | Early stopping patience |

**Output:** `models/gru_best.pt`

### Gradio WebUI (`app.py`)

| Tab | Function |
|-----|----------|
| ğŸ¬ **Video Analysis** | Upload video â†’ YOLO detection + GRU anomaly scoring |
| ğŸ–¼ï¸ **Image Detection** | Single-image YOLO detection (no temporal analysis) |
| ğŸ“Š **Batch Process** | Analyze a folder of videos/clips |
| â„¹ï¸ **About** | Pipeline docs and quick-start guide |

---

## Datasets

See [`datasets/README.md`](datasets/README.md) for download instructions and structure details.

| Dataset | Purpose | Classes |
|---------|---------|---------|
| [VisDrone2019-DET](https://github.com/VisDrone/VisDrone-Dataset) | Drone object detection | 10 (pedestrian, car, bus, â€¦) |
| [UCF-Crime](https://www.crcv.ucf.edu/projects/real-world/) | Anomaly classification | 13 crime types + Normal |

---

## Tech Stack

- **Detection**: [Ultralytics](https://docs.ultralytics.com/) YOLOv26n
- **Deep Learning**: [PyTorch](https://pytorch.org/) 2.10+ (CUDA 13.0)
- **UI**: [Gradio](https://gradio.app/) 6.8+
- **Env**: [uv](https://docs.astral.sh/uv/) for dependency management
- **Metrics**: scikit-learn (AUC-ROC, classification report)

---

## License

MIT
